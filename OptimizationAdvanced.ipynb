{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OptimizationAdvanced.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOl8rYQh+dGhX9m/A5q/R/B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rodelafue/MLBI/blob/master/OptimizationAdvanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8BzfrTkfvUS"
      },
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_VLOG_LEVEL'] = '0'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.WARNING)\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "print(\"Version: \", tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thPhss5Tf2rh"
      },
      "source": [
        "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
        "# Option 1\n",
        "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
        "\n",
        "# Constants\n",
        "a = tf.constant(2, shape=(), dtype=tf.float32, name='a') \n",
        "b = tf.constant(8, shape=(), dtype=tf.float32, name='a') \n",
        "\n",
        "# Variables\n",
        "x = tf.Variable(3, name='x', trainable=True, dtype=tf.float32)\n",
        "y = tf.Variable(2, name='y', trainable=True, dtype=tf.float32)\n",
        "\n",
        "trainable_variables = [x, y]\n",
        "\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
        "loss = lambda: x**2 + y**2 + a*x + b*y\n",
        "\n",
        "for k in tf.range(100, dtype=tf.int64):\n",
        "    print(\"iter= %s, x = %.4f, y = %.4f, loss = %.4f \" % (k.numpy(), x.numpy(), y.numpy(), loss().numpy()))\n",
        "    opt.minimize(loss, var_list=trainable_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ognx_5J7gHdW"
      },
      "source": [
        "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
        "# Alternativa 2\n",
        "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
        "from tensorflow.python.training import gradient_descent\n",
        "\n",
        "@tf.function\n",
        "def f_():\n",
        "    f = x**2 + y**2 + a*x + b*y\n",
        "    return f\n",
        "\n",
        "x = tf.Variable(3, name='x', trainable=True, dtype=tf.float32) # trainable=False\n",
        "y = tf.Variable(2, name='y', trainable=True, dtype=tf.float32)\n",
        "\n",
        "for _ in tf.range(20, dtype=tf.int64):\n",
        "    print(\"x = %.4f, y = %.4f, loss = %.4f \" % (x.numpy(), y.numpy(), f_().numpy()))\n",
        "    opt = gradient_descent.GradientDescentOptimizer(0.1).minimize(f_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuMHl49jf7uX"
      },
      "source": [
        "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
        "# Alternativa 3\n",
        "#$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
        "\n",
        "def f_xy(x,y):\n",
        "    f = x**2 + y**2 + a*x + b*y\n",
        "    return f\n",
        "\n",
        "x = tf.Variable(3, name='x', trainable=True, dtype=tf.float32)\n",
        "y = tf.Variable(2, name='y', trainable=True, dtype=tf.float32)\n",
        "\n",
        "trainable_variables = [x, y]\n",
        "opt = tf.optimizers.Adam(learning_rate=0.1)\n",
        "for step in tf.range(200, dtype=tf.int64):\n",
        "    with tf.GradientTape() as tape:\n",
        "      tape.watch(x)\n",
        "      tape.watch(y)\n",
        "      f = f_xy(x=x, y=y)\n",
        "      gradients = tape.gradient(f, trainable_variables)\n",
        "    print(\"x = %.4f, y = %.4f, loss = %.4f \" % (x.numpy(), y.numpy(), f.numpy()))\n",
        "    print('Gradient X = ', gradients[0], 'Gradient Y = ', gradients[1])\n",
        "    opt.apply_gradients(zip(gradients, trainable_variables))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}